{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Setup complete. Using torch 2.0.1 CPU\n"
     ]
    }
   ],
   "source": [
    "# install dependencies as necessary\n",
    "!pip install -qr /Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5/requirements.txt  # install dependencies (ignore errors)\n",
    "import torch\n",
    "\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "# from utils.google_utils import gdrive_download  # to download models/datasets\n",
    "\n",
    "# clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (1.1.6)\n",
      "Requirement already satisfied: certifi==2022.12.7 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (2022.12.7)\n",
      "Requirement already satisfied: chardet==4.0.0 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: matplotlib in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (1.22.3)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (9.4.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: requests in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (2.28.1)\n",
      "Requirement already satisfied: six in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: supervision in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (0.14.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (1.26.14)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (4.64.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (6.0)\n",
      "Requirement already satisfied: requests-toolbelt in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from roboflow) (0.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from matplotlib->roboflow) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from matplotlib->roboflow) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from matplotlib->roboflow) (22.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from requests->roboflow) (2.0.4)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /Users/damodargupta/anaconda3/lib/python3.10/site-packages (from supervision->roboflow) (1.10.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in plasticDetectionInRivers-3 to yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6590/6590 [00:03<00:00, 2138.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to plasticDetectionInRivers-3 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232/232 [00:00<00:00, 2771.28it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "project = rf.workspace(\"plasticdetection-kr0gi\").project(\"plasticdetectioninrivers\")\n",
    "dataset = project.version(3).download(\"yolov5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "- plastic\n",
      "nc: 1\n",
      "roboflow:\n",
      "  license: CC BY 4.0\n",
      "  project: plasticdetectioninrivers\n",
      "  url: https://universe.roboflow.com/plasticdetection-kr0gi/plasticdetectioninrivers/dataset/3\n",
      "  version: 3\n",
      "  workspace: plasticdetection-kr0gi\n",
      "test: /Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/test\n",
      "train: /Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/train\n",
      "val: /Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/valid\n"
     ]
    }
   ],
   "source": [
    "%cat /Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/data.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining model config and architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of classes based on YAML\n",
    "import yaml\n",
    "with open(\"/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# YOLOv5 ðŸš€ by Ultralytics, AGPL-3.0 license\n",
      "\n",
      "# Parameters\n",
      "nc: 80  # number of classes\n",
      "depth_multiple: 0.67  # model depth multiple\n",
      "width_multiple: 0.75  # layer channel multiple\n",
      "anchors:\n",
      "  - [10,13, 16,30, 33,23]  # P3/8\n",
      "  - [30,61, 62,45, 59,119]  # P4/16\n",
      "  - [116,90, 156,198, 373,326]  # P5/32\n",
      "\n",
      "# YOLOv5 v6.0 backbone\n",
      "backbone:\n",
      "  # [from, number, module, args]\n",
      "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
      "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
      "   [-1, 3, C3, [128]],\n",
      "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
      "   [-1, 6, C3, [256]],\n",
      "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
      "   [-1, 9, C3, [512]],\n",
      "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
      "   [-1, 3, C3, [1024]],\n",
      "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
      "  ]\n",
      "\n",
      "# YOLOv5 v6.0 head\n",
      "head:\n",
      "  [[-1, 1, Conv, [512, 1, 1]],\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
      "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
      "   [-1, 3, C3, [512, False]],  # 13\n",
      "\n",
      "   [-1, 1, Conv, [256, 1, 1]],\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
      "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
      "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
      "\n",
      "   [-1, 1, Conv, [256, 3, 2]],\n",
      "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
      "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
      "\n",
      "   [-1, 1, Conv, [512, 3, 2]],\n",
      "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
      "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
      "\n",
      "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
      "  ]\n"
     ]
    }
   ],
   "source": [
    "#this is the model configuration we will use\n",
    "%cat /Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5/models/yolov5m.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate /Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5/models/custom_yolov5m.yaml\n",
    "\n",
    "# parameters\n",
    "nc: {num_classes}  # number of classes\n",
    "depth_multiple: 2  # model depth multiple\n",
    "width_multiple: 1  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, BottleneckCSP, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, BottleneckCSP, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, BottleneckCSP, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Custom Yolo v5 detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 Âµs, sys: 1e+03 ns, total: 2 Âµs\n",
      "Wall time: 3.1 Âµs\n",
      "/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=./models/custom_yolov5m.yaml, data=/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=20, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5m_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
      "YOLOv5 ðŸš€ v7.0-224-g6262c7fe Python-3.10.9 torch-2.0.1 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  6    284800  models.common.BottleneckCSP             [128, 128, 6]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1 18   3107072  models.common.BottleneckCSP             [256, 256, 18]                \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1 18  12407296  models.common.BottleneckCSP             [512, 512, 18]                \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n",
      "  9                -1  6  18105344  models.common.BottleneckCSP             [1024, 1024, 6, False]        \n",
      " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  6   4792832  models.common.BottleneckCSP             [1024, 512, 6, False]         \n",
      " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  6   1200384  models.common.BottleneckCSP             [512, 256, 6, False]          \n",
      " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  6   4530688  models.common.BottleneckCSP             [512, 512, 6, False]          \n",
      " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  6  18105344  models.common.BottleneckCSP             [1024, 1024, 6, False]        \n",
      " 24      [17, 20, 23]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "custom_YOLOv5m summary: 653 layers, 75075894 parameters, 75075894 gradients\n",
      "\n",
      "Transferred 58/1089 items from yolov5m.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 179 weight(decay=0.0), 190 weight(decay=0.00046875), 182 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/pl\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<00:00, 437.34it\u001b[0m\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/Users/damodargupta/anaconda3/lib/python3.10/site-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5/train.py\", line 647, in <module>\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/multiprocessing/spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/runpy.py\", line 289, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5/train.py\", line 61, in <module>\n",
      "    from utils.loggers import Loggers\n",
      "  File \"/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5/utils/loggers/__init__.py\", line 23, in <module>\n",
      "    main(opt)\n",
      "  File \"/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5/train.py\", line 536, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5/train.py\", line 195, in train\n",
      "    train_loader, dataset = create_dataloader(train_path,\n",
      "  File \"/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5/utils/dataloaders.py\", line 145, in create_dataloader\n",
      "    from torch.utils.tensorboard import SummaryWriter\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
      "    return loader(dataset,\n",
      "  File \"/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5/utils/dataloaders.py\", line 165, in __init__\n",
      "    self.iterator = super().__iter__()\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 441, in __iter__\n",
      "    from .writer import FileWriter, SummaryWriter  # noqa: F401\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py\", line 16, in <module>\n",
      "    return self._get_iterator()\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 388, in _get_iterator\n",
      "    from ._embedding import (\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/torch/utils/tensorboard/_embedding.py\", line 9, in <module>\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1042, in __init__\n",
      "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
      "    return getattr(load_once(self), attr_name)\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
      "    cache[arg] = f(arg)\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/tensorboard/lazy.py\", line 50, in load_once\n",
      "    module = load_fn()\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
      "    import tensorflow\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/tensorflow/__init__.py\", line 46, in <module>\n",
      "    from ._api.v2 import __internal__\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    w.start()\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/multiprocessing/process.py\", line 121, in start\n",
      "    from . import autograph\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 975, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_data\n",
      "KeyboardInterrupt\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/multiprocessing/context.py\", line 288, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\n",
      "    super().__init__(process_obj)\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/Users/damodargupta/anaconda3/lib/python3.10/multiprocessing/popen_spawn_posix.py\", line 62, in _launch\n",
      "    f.write(fp.getbuffer())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# train yolov5s on custom data for 100 epochs\n",
    "# time its performance\n",
    "%time\n",
    "%cd /Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/yolov5\n",
    "!python train.py --img 640 --batch 20 --epochs 100 --data '/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/data.yaml' --cfg ./models/custom_yolov5m.yaml --weights 'yolov5m.pt' --name yolov5m_results  --cache"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the trained model from roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "project = rf.workspace().project(\"plasticdetectioninrivers\")\n",
    "model = project.version(3).model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'x': 417.0, 'y': 302.5, 'width': 14.0, 'height': 19.0, 'confidence': 0.7532166242599487, 'class': 'plastic', 'class_id': 0, 'image_path': '/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/train/images/DJI_0020_jpg.rf.68907455640f46deb12baea018577926.jpg', 'prediction_type': 'ObjectDetectionModel'}, {'x': 196.5, 'y': 396.0, 'width': 19.0, 'height': 22.0, 'confidence': 0.7387670278549194, 'class': 'plastic', 'class_id': 0, 'image_path': '/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/train/images/DJI_0020_jpg.rf.68907455640f46deb12baea018577926.jpg', 'prediction_type': 'ObjectDetectionModel'}, {'x': 284.0, 'y': 408.0, 'width': 16.0, 'height': 16.0, 'confidence': 0.44433990120887756, 'class': 'plastic', 'class_id': 0, 'image_path': '/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/train/images/DJI_0020_jpg.rf.68907455640f46deb12baea018577926.jpg', 'prediction_type': 'ObjectDetectionModel'}], 'image': {'width': '640', 'height': '640'}}\n"
     ]
    }
   ],
   "source": [
    "# infer on a local image\n",
    "print(model.predict(\"/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/plasticDetectionInRivers-3/train/images/DJI_0020_jpg.rf.68907455640f46deb12baea018577926.jpg\", confidence=40, overlap=30).json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize your prediction\n",
    "model.predict(\"/Users/damodargupta/Downloads/AI Hackathon REVA University/Train/DJI_0071.jpg\", confidence=40, overlap=30).save(\"/Users/damodargupta/Desktop/projects/PlasticDetectionInRivers/prediction.jpg\")\n",
    "\n",
    "# infer on an image hosted elsewhere\n",
    "# print(model.predict(\"URL_OF_YOUR_IMAGE\", hosted=True, confidence=40, overlap=30).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<roboflow.util.prediction.PredictionGroup at 0x1545f38e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize your prediction\n",
    "model.predict(\"/Users/damodargupta/Downloads/AI Hackathon REVA University/Train/DJI_0071.jpg\")\n",
    "\n",
    "# infer on an image hosted elsewhere\n",
    "# print(model.predict(\"URL_OF_YOUR_IMAGE\", hosted=True, confidence=40, overlap=30).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{34853: {0: b'\\x02\\x03\\x00\\x00', 1: 'N', 2: (10.0, 53.759, 0.0), 3: 'E', 4: (106.0, 41.6141, 0.0), 5: b'\\x00', 6: 38.762}, 296: 2, 34665: 212, 271: 'DJI', 272: 'FC300X', 305: 'Adobe Photoshop CC 2015 (Windows)', 274: 1, 306: '2021:05:20 16:25:09', 282: 240.0, 283: 240.0, 36864: b'0230', 37377: 10.287712, 37378: 2.970854, 36867: '2021:05:20 10:00:45', 36868: '2021:05:20 10:00:45', 37380: 0.0, 37381: 2.0, 37382: 0.0, 37383: 2, 37384: 0, 37385: 32, 37386: 3.61, 40961: 65535, 40962: 3992, 41989: 20, 41990: 0, 40963: 2992, 41992: 0, 41993: 0, 41994: 0, 41996: 0, 41728: b'\\x03', 33434: 0.0008, 33437: 2.8, 41729: b'\\x01', 34850: 8176, 41985: 0, 34855: 100, 41986: 1, 41987: 0, 42033: '2014031100', 42034: (20.7, 20.7, nan, nan), 42036: '20.7 mm', 41988: 0.0, 41991: 0}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "\n",
    "def get_geotagging_info(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    exif_data = image._getexif()\n",
    "    print(exif_data)\n",
    "    geotagging_info = None\n",
    "    for tag, value in exif_data.items():\n",
    "        tag_name = TAGS.get(tag, tag)\n",
    "        if tag_name == 'GPSInfo':\n",
    "            geotagging_info = {GPSTAGS.get(t, t): v for t, v in value.items()}\n",
    "    return geotagging_info\n",
    "\n",
    "image_path = \"/Users/damodargupta/Downloads/AI Hackathon REVA University/Train/DJI_0025.jpg\"\n",
    "geotag_info = get_geotagging_info(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPSVersionID': b'\\x02\\x03\\x00\\x00',\n",
       " 'GPSLatitudeRef': 'N',\n",
       " 'GPSLatitude': (10.0, 53.759, 0.0),\n",
       " 'GPSLongitudeRef': 'E',\n",
       " 'GPSLongitude': (106.0, 41.6141, 0.0),\n",
       " 'GPSAltitudeRef': b'\\x00',\n",
       " 'GPSAltitude': 38.762}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geotag_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
